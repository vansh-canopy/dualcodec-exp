{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xabieririzar/xabi-dualcodec/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import snapshot_download\n",
    "from datasets import concatenate_datasets\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_paths = [f\"EN-B00000{i}.tar\" for i in range(0, 10)]\n",
    "local_dir = \"../emilia_dataset\"\n",
    "max_shards = 10\n",
    "language = \"EN\"\n",
    "ds_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1000 files: 100%|██████████| 1000/1000 [28:36<00:00,  1.72s/it] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/xabieririzar/emilia_dataset'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot_download(\n",
    "    repo_id=\"amphion/Emilia-Dataset\",\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=\"../emilia_dataset\",\n",
    "    allow_patterns=\"Emilia/EN/EN-B000*.tar\",\n",
    "    max_workers=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dir = \"../emilia_dataset/Emilia/EN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EN-B000000.tar',\n",
       " 'EN-B000001.tar',\n",
       " 'EN-B000002.tar',\n",
       " 'EN-B000003.tar',\n",
       " 'EN-B000004.tar',\n",
       " 'EN-B000005.tar',\n",
       " 'EN-B000006.tar',\n",
       " 'EN-B000007.tar',\n",
       " 'EN-B000008.tar',\n",
       " 'EN-B000009.tar']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading shards:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard 1/10: ../../../xabi-dualcodec/EN-B000000.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating en split: 24932 examples [00:06, 3766.56 examples/s]\n",
      "Loading shards:  10%|█         | 1/10 [00:06<01:00,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard 2/10: ../../../xabi-dualcodec/EN-B000001.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating en split: 25938 examples [00:06, 3763.81 examples/s]\n",
      "Loading shards:  20%|██        | 2/10 [00:13<00:54,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard 3/10: ../../../xabi-dualcodec/EN-B000002.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating en split: 26797 examples [00:07, 3639.76 examples/s]\n",
      "Loading shards:  30%|███       | 3/10 [00:20<00:49,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard 4/10: ../../../xabi-dualcodec/EN-B000003.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating en split: 23608 examples [00:06, 3695.09 examples/s]\n",
      "Loading shards:  40%|████      | 4/10 [00:27<00:40,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard 5/10: ../../../xabi-dualcodec/EN-B000004.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating en split: 21356 examples [00:05, 3713.38 examples/s]\n",
      "Loading shards:  50%|█████     | 5/10 [00:33<00:32,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard 6/10: ../../../xabi-dualcodec/EN-B000005.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating en split: 25399 examples [00:07, 3319.12 examples/s]\n",
      "Loading shards:  60%|██████    | 6/10 [00:40<00:27,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard 7/10: ../../../xabi-dualcodec/EN-B000006.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating en split: 26907 examples [00:07, 3803.23 examples/s]\n",
      "Loading shards:  70%|███████   | 7/10 [00:47<00:20,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard 8/10: ../../../xabi-dualcodec/EN-B000007.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating en split: 24270 examples [00:06, 3762.31 examples/s]\n",
      "Loading shards:  80%|████████  | 8/10 [00:54<00:13,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard 9/10: ../../../xabi-dualcodec/EN-B000008.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating en split: 24167 examples [00:06, 3778.44 examples/s]\n",
      "Loading shards:  90%|█████████ | 9/10 [01:00<00:06,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard 10/10: ../../../xabi-dualcodec/EN-B000009.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating en split: 23715 examples [00:06, 3806.75 examples/s]\n",
      "Loading shards: 100%|██████████| 10/10 [01:07<00:00,  6.71s/it]\n"
     ]
    }
   ],
   "source": [
    "for i, tar_path in enumerate(tqdm(tar_paths[:max_shards], desc=\"Loading shards\"), start=1):\n",
    "    rel_path = os.path.relpath(tar_path, start=local_dir)\n",
    "    print(f\"Loading shard {i}/{max_shards}: {rel_path}\")\n",
    "    ds = load_dataset(\n",
    "        local_dir,\n",
    "        data_files={language.lower(): tar_path},\n",
    "        split=language.lower()\n",
    "    )\n",
    "    ds_list.append(ds)\n",
    "\n",
    "big_ds = concatenate_datasets(ds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['json', 'mp3', '__key__', '__url__'],\n",
       "    num_rows: 247089\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "big_ds = concatenate_datasets(ds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset from the downloaded repository\n",
    "dataset = load_dataset(\n",
    "    repo_path,\n",
    "    data_files={\"train\": \"DE/*.tar\"},  # Only German data (~10% of full dataset)\n",
    "    split=\"train\",\n",
    "    streaming=False\n",
    ")\n",
    "\n",
    "# Alternative: If you want to control exact percentage, you can slice after loading\n",
    "# dataset = dataset.select(range(int(len(dataset) * 0.1)))  # Take only 10%\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} samples\")\n",
    "print(f\"Dataset cached in: {cache_dir}\")\n",
    "print(f\"Repository downloaded to: {repo_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
