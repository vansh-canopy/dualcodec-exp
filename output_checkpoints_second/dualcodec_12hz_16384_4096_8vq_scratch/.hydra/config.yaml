data:
  dataloader:
    _target_: torch.utils.data.DataLoader
    dataset: ${..datalist}
    batch_size: null
    num_workers: 18
  gluster_opener:
    _target_: dualcodec.dataset.processor.gluster_opener
    _partial_: true
    manual_dist_sampler: true
  get_tokenizer:
    _target_: whisper.tokenizer.get_tokenizer
    _partial_: true
    multilingual: true
    num_languages: 100
    language: en
    task: transcribe
  tokenize:
    _target_: dualcodec.dataset.processor.tokenize
    _partial_: true
    get_tokenizer: ${..get_tokenizer}
    allowed_special: all
  gluster_filter:
    _target_: dualcodec.dataset.processor.gluster_filter
    _partial_: true
    is_emilia: true
    max_length: 2000
    min_length: 150
    token_max_length: 300
    ignore_text: true
  resample:
    _target_: dualcodec.dataset.processor.resample
    _partial_: true
    resample_rate: ${trainer.sample_rate}
  shuffle:
    _target_: dualcodec.dataset.processor.shuffle
    _partial_: true
    shuffle_size: 60000
  normalize:
    _target_: dualcodec.dataset.processor.normalize
    _partial_: true
    use_kana: true
  batch:
    _target_: dualcodec.dataset.processor.batch
    _partial_: true
    batch_type: static
    batch_size: ${trainer.batch_size}
    ignore_text: true
    max_frames_in_batch: null
  gluster_padding:
    _target_: dualcodec.dataset.processor.gluster_padding
    _partial_: true
    use_spk_embedding: false
    return_speech: true
    ignore_text: true
  w2v_feat_extractor:
    _target_: transformers.SeamlessM4TFeatureExtractor.from_pretrained
    _partial_: false
    pretrained_model_name_or_path: ${machine.w2v_path}
  w2v_feature:
    _target_: dualcodec.dataset.processor.w2v_feature
    _partial_: true
    feature_extractor: ${..w2v_feat_extractor}
  dataset:
    _target_: dualcodec.dataset.emilia_hf.EmiliaDataset
    is_debug: false
  datalist_tmp:
    _target_: dualcodec.dataset.dataset.DataList
    lists: ${..dataset}
    shuffle: false
    partition: false
  datalist:
    _target_: dualcodec.dataset.dataset.prepare_gluster_dataset
    data_list: ${..datalist_tmp}
    data_pipeline: ${..data_pipeline}
  segment_speech:
    _target_: dualcodec.dataset.processor.segment_speech
    _partial_: true
    segment_length: 76800
  data_pipeline:
  - ${..gluster_opener}
  - ${..gluster_filter}
  - ${..resample}
  - ${..segment_speech}
  - ${..w2v_feature}
  - ${..batch}
  - ${..gluster_padding}
machine:
  w2v_path: ./w2v-bert-2.0
  ckpt_root_path: ./dualcodec_ckpts
  log_dir: ./output_checkpoints_second
  init_model_path: ./dualcodec_ckpts
model:
  SAMPLE_RATE: 24000
  model:
    _target_: dualcodec.model_codec.DualCodec
    sample_rate: ${..SAMPLE_RATE}
    encoder_rates:
    - 4
    - 5
    - 6
    - 8
    - 2
    decoder_rates:
    - 2
    - 8
    - 6
    - 5
    - 4
    encoder_dim: 32
    decoder_dim: 1536
    n_codebooks: 7
    quantizer_dropout: 1.0
    codebook_size: 4096
    semantic_codebook_size: 16384
    is_causal: true
    semantic_downsample_factor: 4
  discriminator:
    _target_: dualcodec.model_codec.Discriminator
    sample_rate: ${..SAMPLE_RATE}
trainer:
  sample_rate: 24000
  max_tokens: 2000
  num_epochs: 10
  batch_size: 16
  exp_name: dualcodec_12hz_16384_4096_8vq_scratch
  args:
    exp_name: ${..exp_name}
    log_level: DEBUG
    seed: 43
    resume: false
    resume_type: resume
  cfg:
    dataloader: null
    log_dir: ${machine.log_dir}
    model: ${model.model}
    semantic_model:
      _target_: dualcodec.dataset.processor._build_semantic_model
      _partial_: false
      semantic_model:
        _target_: transformers.Wav2Vec2BertModel.from_pretrained
        _partial_: false
        pretrained_model_name_or_path: ${machine.w2v_path}
      mean_var_path: ${machine.ckpt_root_path}/w2vbert2_mean_var_stats_emilia.pt
      repcodec_model: null
      repcodec_path: null
    discriminator_model: ${model.discriminator}
    train:
      gradient_accumulation_step: 1
      find_unused_parameters: true
      tracker: wandb
      max_epoch: 1000
      save_checkpoint_stride:
      - 200
      keep_last:
      - 1
      run_eval: true
      dataloader:
        num_worker: 4
        pin_memory: true
        persistent_workers: true
      use_dynamic_batchsize: true
      optimizer:
        _target_: torch.optim.AdamW
        _partial_: true
        lr: 5.0e-05
        betas:
        - 0.8
        - 0.9
      adamw:
        lr: 0.0001
      scheduler:
        warmup_steps: 5000
        total_steps: 1000000
        min_lr: 5.0e-05
      exponentiallr:
        gamma: 0.999999
      max_sentences: 64
      max_steps: 400000
      disable_mixed_precision: true
    semantic_vq: true
    lambda_semantic_commitment_loss: 0.25
    lambda_semantic_codebook_loss: 1.0
    lambda_distill_loss: 15.0
    add_semantic_spec_loss: true
  trainer:
    _target_: dualcodec.model_codec.trainer.Trainer
    cfg: ${..cfg}
    args: ${..args}
